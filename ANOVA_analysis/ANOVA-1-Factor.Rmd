---
title: "Análisis de la varianza de un factor"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r paquetes, echo=FALSE, message=FALSE}
if (!require(readxl)) install.packages('readxl')
if (!require(ggpubr)) install.packages('ggpubr')
# if (!require(car)) install.packages('car')
if (!require(agricolae)) install.packages('agricolae')
```

```{r data, echo=FALSE}
df <- read_excel("Datos/datos_A1F.xlsx",
                    sheet = "datos")

VD <- names(df[1])
VI1 <- names(df[2])

names(df) <- c("VD", "VI1")

df[[2]] <- as.factor(df[[2]])
```

## Información sobre los datos

En este informe se analizan los datos para la variable *`r VD`* en función de  *`r VI1`*, variable de agrupamiento con los niveles: **`r levels(df$VI1)`**.  

Tabla 1: Estadísticos descriptivos de los datos
```{r, echo=FALSE}
tapply(df$VD, df$VI1, FUN=summary)
```

Tabla 2: Valor de la media y desviación estándar por grupos
```{r, echo=FALSE}
ag <- aggregate(. ~ VI1, df, function(x) c(mean = mean(x), sd = sd(x)))
ag
```


Para aplicar el test estadístico más adecuado debemos comprobar algunas características de la distribución de datos, como la normalidad (que la distribución de datos se acerque a una distribución normal) o la varianza entre grupos sea igual. Que se cumplan estas condiciones son requisitos previos para poder usar el resultado de una análisis de varianza paramétrico (como ANOVA). La homogeneidad de la varianza se estimará directamente sobre los datos y la normalidad se comprobará sobre los residuos del modelo de ajuste ANOVA.

## Comprobar homogeneidad de la varianza

Tabla 3: Resultados de la prueba de homogeneidad de la varianza entre grupos mediante tres test para homogeneidad de la varianza. Bartlett's test (sensible a datos no normales), Levene's test (más robusto antes desviaciones de los datos de la normalidad) y Fligner's test (para datos no paramétricos). Si el valor de p es mayor de 0.05 se asume que no hay diferencias entre las varianzas y podríamos asumir homogeneidad para los diferentes tratamientos.

```{r, echo=FALSE}
bartlett.test(VD ~ VI1, data=df)
```

```{r, echo=FALSE}
# leveneTest(VD ~ VI1, data = df)
```

```{r, echo=FALSE}
fligner.test(VD ~ VI1, data = df)
```

## ANOVA de un factor
Cuando la variable independiente tiene más de tres grupos no podemos usar estadísticos como la t de Student por lo que se necesita un análisis de la varianza como ANOVA (si los datos cumplen con los requisitos). En este caso aplicaremos una ANOVA de un factor a nuestros datos.

Tabla 4: Resultados del ANOVA para un nivel de significación de 0.05. Si valor de Pr(>F) es menor de 0.05, se asume que hay un efecto significativo de los tratamientos sobre la variable dependiente (aunque aun no sabemos qué grupo es mayor o menos que otros). El nivel de significación vendrá determinado por el número de asteríscos tal como indica la línea "Signif. codes"

```{r, echo= FALSE}
res.aov1 <- aov(VD ~ VI1, data = df)
summary(res.aov1)
```


## Prueba de normalidad sobre los residuos del ANOVA
Antes de dar por bueno el resultado del ANOVA debemos comprobar que se cumple el criterio de normalidad. Una forma de acerlo es evaluar si los residuos del modelo ANOVA se ajustan a una normal. Esto podemos hacerlo mediante un test estadísico, Shapiro-Wilk Normaliy Test, o una representación tipo Q-Q plot (Figura 1). 

Tabla 5: Resultados del Shapiro-Wilk Normality Test para los datos analizados. Si el valor de p es mayo de 0.05 se asume que no hay diferencias entre la distribución de nuestros datos y una distribución normal. Se cumpliría, en este caso, el requisito de normalidad

```{r, echo=FALSE}
shapiro.test(x = residuals(res.aov1))
```

```{r, echo=FALSE, fig.cap="Figura 1: Q-Q plot de los datos. En una distribución normal los residuos se agregarían alrededor de la línea. Los datos se se desvían de la normalidad aparecen indicados con el número de fila en la tabla original y, si son pocos, podrían considerarse datos raros u outliers"}
plot(res.aov1, 2)
```


## Grupos homogéneos con Tukey HSD
Si los datos cumplen con los requisitos para el ANOVA y el resultado de este es significativo, podemos determinar qué grupos son diferentes mediante los grupos homogéneos establecidos con un test como el Tukey HSD test.

Tabla 6: Resultados del Tukey HSD test para determinar grupos homogéneso mediante la comparación de las medias de cada grupo. Grupos que comparte una letra se consideran que no son diferentes respecto a su media de la distribución
```{r, echo=FALSE}
HSD.test(res.aov1, "VI1", group = TRUE, console = TRUE)
```

# Análisis no paramétrico, equivalente a ANOVA, mediante test de Kruskal-Wallis

En caso de que no se cumplan los requisitos previos para aplicar un análisis de ANOVA utilizaremos una alternativa para datos no paramétricos como es el Kruskal-Wallis Rank Sum Test.


Tabla 7: Resultados del Kruskal-Wallis Rank Sum Test. Si valor de p es menor de 0.05, se asume que hay un efecto significativo de los tratamientos sobre la variable dependiente (aunque aun no sabemos qué grupo es mayor o menos que otros).
```{r, echo=FALSE}
kruskal.test(VD ~VI1, data = df)
```

## Comparación múltiple entre grupos
En una comparación de medias para datos no paramétricos, tras comprobar que hay efecto significativo del tratamiento mediante el Kruskal-Wallis Rank Sum Test, aplicaremos un test de comparación por pares entre niveles de grupo con correcciones para pruebas múltiples

Tabla 8: Resultados del Paiwise Wilconxon Rank Sum Test para determinar grupos homogéneso mediante la comparación de las medias de cada grupo. En la tabla de contingencia aparece el valor de p para cada par de grupos comparado. Si valor de p es menor de 0.05, se asume que hay una diferencia significativa entre la media de ese par de grupos
```{r, echo=FALSE, warning=FALSE}
pairwise.wilcox.test(df$VD, df$VI1,
                 p.adjust.method = "BH")
```